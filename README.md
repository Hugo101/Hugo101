### Hi there ðŸ‘‹, I'm Changbin. Nice to meet you.

<!--
**Hugo101/Hugo101** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...

- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

- ðŸ”­ Iâ€™m currently pursuing my Ph.D. in the [Department of Computer Science](https://cs.utdallas.edu/) at the University of Texas at Dallas, supervised by [Prof. Feng Chen](https://personal.utdallas.edu/~fxc190007/). I was a research intern at **[Meta AI](https://ai.meta.com/)** and **[Bosch Center for AI](https://www.bosch-ai.com/)**. During my tenure at Meta AI, I contributed to a multimodal recurring transfer learning project. Subsequently, at BCAI, I focused on the sparsity of the **Multimodal Foundation Models (Vision-Language Models)**.
  
- ðŸŒ± My research is in the field of Deep Learning, with a focus on **low-resource learning (meta/few-shot/semi/self-supervised learning)**, **uncertainty estimation**, **robustness**, and **efficiency** in traditional CNNs and vision-language models. My goal is to ensure AI systems safe, robust, reliable and trustworthy. Iâ€™m also very interested in **Generative AI** (large language models (LLMs), and diffusion models), and exploring along these directions. 
    - **Robust Meta-Learning**
      - [PLATINUM: Semi-Supervised Model Agnostic Meta-Learning using Submodular Mutual Information.](https://proceedings.mlr.press/v162/li22k/li22k.pdf)\
	**Changbin Li**, Suraj Kothawade, Feng Chen, Rishabh Iyer
        International Conference on Machine Learning (**ICML**), 2022.
	  - [A Nested Bi-Level Optimization for Robust Few Shot Learning.](https://arxiv.org/pdf/2011.06782.pdf)\
            Krishnateja Killamsetty*, **Changbin Li\***, Chen Zhao, Rishabh Iyer, Feng Chen. (**\* Equal Contribution**) \
      AAAI Conference on Artificial Intelligence (**AAAI**), 2022.
    - **Uncertainty Quantification**
      - [Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty.](https://openreview.net/forum?id=A7t7z6g6tM)\
        **Changbin Li**, Kangshuo Li, Yuzhe Ou, Lance M. Kaplan, Audun JÃ¸sang, Jin-Hee Cho, DONG HYUN JEONG, Feng Chen.\
        International Conference on Learning Representations (**ICLR**), 2024 

    - **Current Work:**
      - Currently investigating uncertainty quantification in vision-language model and LLMs to improve their decision-making robustness.
        
- ðŸ’¬ I'd like to write some blogs sometimes, including **[Paper Notes](https://lichangbin.gitbook.io/paper_notes/)** and **[Study Notes](https://lichangbin.gitbook.io/studynotes/)**. Recently, I am summarizing my previous notes on **[Generative AI](https://lichangbin.gitbook.io/generative-models/)**.

- ðŸ‘¯ **Iâ€™m looking for internship opportunities for Spring/Summer 2024, and seeking full-time roles for 2024**.
  
- ðŸ“« Feel free to contact me via email at <changbin.li@utdallas.edu> or <lichangbin@outlook.com>
